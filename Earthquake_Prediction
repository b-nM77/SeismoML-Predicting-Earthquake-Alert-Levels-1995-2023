{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":6423640,"sourceType":"datasetVersion","datasetId":2941956}],"dockerImageVersionId":31153,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/madhurabn/class-imbalance-in-earthquake-prediction?scriptVersionId=272229757\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"# Predicting Earthquake Alert Levels — Handling Class Imbalance with ML & Cross-Validation\n\nPredicting earthquake alert levels — green, yellow, orange, or red — is an important task for understanding potential seismic impact and supporting early warning systems. This notebook develops a complete machine learning workflow using global earthquake records collected between 2001 and 2023, containing parameters such as magnitude, depth, seismic intensity (MMI, CDI), and geographic information including continent and country. \n\nA major challenge in this data is class imbalance, where minor “green” alerts greatly outnumber rare but high-severity “orange” and “red” events. The workflow is designed to build a model that maintains both strong overall accuracy and balanced performance across all alert categories, ensuring that critical but infrequent events are not overlooked.\n\nTo address the imbalance problem, three techniques were evaluated — a baseline model without correction, class weighting to adjust algorithmic bias, and SMOTE for synthetic oversampling of minority classes. \n\nThese approaches were tested across Logistic Regression, Random Forest, and XGBoost classifiers, with results validated using repeated stratified cross-validation for reliability. Logistic Regression achieved the highest single test Macro-F1 score (0.876), while SMOTE-enhanced XGBoost delivered the most balanced and stable performance (cross-validation Macro-F1 ≈ 0.68–0.70, Std ≈ 0.07–0.08). The findings highlight the importance of class-imbalance handling in seismic prediction, showing that techniques like SMOTE and mild regularization can significantly improve generalization and fairness in earthquake alert classification.\n\n## Methodology Summary\n\n| Step                              | Description                                                                                                                                                                      |\n| --------------------------------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n| **1. Data Preprocessing**         | Encoded categorical features (`magType`, `continent`, `country`, `alert`) using Label Encoding and scaled numeric attributes (`magnitude`, `depth`, etc.) with `StandardScaler`. |\n| **2. Stratified Sampling**        | Used **StratifiedShuffleSplit** to create a balanced 75–25 train-test split, ensuring each alert category was proportionally represented.                                        |\n| **3. Model Selection**            | Evaluated three ML algorithms: **Logistic Regression**, **Random Forest**, and **XGBoost**, chosen for their interpretability and robustness.                                    |\n| **4. Class-Imbalance Strategies** | Compared three approaches: <br> **Baseline** (no balancing) <br> **Class Weights** (model-aware balancing) <br> **SMOTE** (synthetic oversampling).                        |\n| **5. Cross-Validation**           | Applied **RepeatedStratifiedKFold (5×3)** for robust performance estimation and variance tracking (`CV_F1_Mean`, `CV_F1_STD`).                                                   |\n| **6. Regularization**             | Applied **mild regularization** (limiting tree depth, min samples per split) to reduce overfitting without full hyperparameter tuning.                                           |\n| **7. Evaluation Metrics**         | Used **Macro-F1 Score** as the primary metric to treat all alert classes equally and **Accuracy** as a secondary indicator of overall correctness.                               |\n| **8. Visualization & Reporting**  | Summarized model performance across imbalance techniques and plotted bar charts comparing test-set Macro-F1 results for all models.                                              |\n","metadata":{}},{"cell_type":"code","source":"# Optional step to make sure proper scikit-leanr version installed\n!pip uninstall -y scikit-learn imbalanced-learn","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-30T22:40:51.204643Z","iopub.execute_input":"2025-10-30T22:40:51.20507Z","iopub.status.idle":"2025-10-30T22:40:52.925027Z","shell.execute_reply.started":"2025-10-30T22:40:51.205042Z","shell.execute_reply":"2025-10-30T22:40:52.923494Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install scikit-learn==1.5.2 imbalanced-learn==0.12.3","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-30T22:40:52.927964Z","iopub.execute_input":"2025-10-30T22:40:52.928818Z","iopub.status.idle":"2025-10-30T22:41:01.160567Z","shell.execute_reply.started":"2025-10-30T22:40:52.928747Z","shell.execute_reply":"2025-10-30T22:41:01.158797Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import sklearn, imblearn\nprint(\"scikit-learn:\", sklearn.__version__)\nprint(\"imbalanced-learn:\", imblearn.__version__)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-30T22:41:01.162314Z","iopub.execute_input":"2025-10-30T22:41:01.162744Z","iopub.status.idle":"2025-10-30T22:41:01.170814Z","shell.execute_reply.started":"2025-10-30T22:41:01.162705Z","shell.execute_reply":"2025-10-30T22:41:01.169254Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Basic libraries\nimport pandas as pd\nimport numpy as np\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.express as px\n\n# Preprocessing & ML libraries\nfrom sklearn.model_selection import train_test_split, cross_val_score\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler\nfrom sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom xgboost import XGBClassifier\n\nimport warnings\nwarnings.filterwarnings('ignore')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-30T22:41:01.172573Z","iopub.execute_input":"2025-10-30T22:41:01.173019Z","iopub.status.idle":"2025-10-30T22:41:01.198738Z","shell.execute_reply.started":"2025-10-30T22:41:01.172963Z","shell.execute_reply":"2025-10-30T22:41:01.1975Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Dataset Overview\n\nThe dataset contains 1000 recorded earthquakes that occurred worldwide between 1995 and 2023.\nEach record includes details about the event’s magnitude, depth, intensity, location, and alert level (green, yellow, orange, red).\n\nAdditional features such as seismic station data, geographic coordinates, and tsunami indicators provide deeper context about the scale and reliability of each event.\nThe target variable alert represents the severity level of the earthquake, making this a multi-class classification problem focused on predicting alert categories using seismic and geographic parameters.","metadata":{}},{"cell_type":"code","source":"# Load dataset\nimport os\nprint(os.listdir(\"/kaggle/input\"))\nprint(os.listdir(\"/kaggle/input/earthquake-dataset\"))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-30T22:41:01.203805Z","iopub.execute_input":"2025-10-30T22:41:01.204201Z","iopub.status.idle":"2025-10-30T22:41:01.244878Z","shell.execute_reply.started":"2025-10-30T22:41:01.204172Z","shell.execute_reply":"2025-10-30T22:41:01.243578Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data = pd.read_csv(\"/kaggle/input/earthquake-dataset/earthquake_1995-2023.csv\")\ndata","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-30T22:41:01.246196Z","iopub.execute_input":"2025-10-30T22:41:01.246521Z","iopub.status.idle":"2025-10-30T22:41:01.280956Z","shell.execute_reply.started":"2025-10-30T22:41:01.246496Z","shell.execute_reply":"2025-10-30T22:41:01.279883Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Data Cleaning and Preprocessing","metadata":{}},{"cell_type":"code","source":"# Drop irrelevant columns\ncols_to_drop = ['title', 'date_time', 'net', 'location']\ndata = data.drop(columns=cols_to_drop)\n\n# Drop rows with missing alert values\ndata = data.dropna(subset=['alert']).reset_index(drop=True)\n\n# Fill missing continent/country if any\ndata['continent'] = data['continent'].fillna('Unknown')\ndata['country'] = data['country'].fillna('Unknown')\n\n# Check missing values\nprint(data.isnull().sum())\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-30T22:41:01.281916Z","iopub.execute_input":"2025-10-30T22:41:01.282217Z","iopub.status.idle":"2025-10-30T22:41:01.297431Z","shell.execute_reply.started":"2025-10-30T22:41:01.28219Z","shell.execute_reply":"2025-10-30T22:41:01.296295Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-30T22:41:01.298377Z","iopub.execute_input":"2025-10-30T22:41:01.298639Z","iopub.status.idle":"2025-10-30T22:41:01.327858Z","shell.execute_reply.started":"2025-10-30T22:41:01.298619Z","shell.execute_reply":"2025-10-30T22:41:01.326681Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data.describe()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-30T22:41:01.328911Z","iopub.execute_input":"2025-10-30T22:41:01.329492Z","iopub.status.idle":"2025-10-30T22:41:01.385617Z","shell.execute_reply.started":"2025-10-30T22:41:01.329464Z","shell.execute_reply":"2025-10-30T22:41:01.384232Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(data['alert'].dtype)\nprint(data['alert'].unique())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-30T22:41:01.387456Z","iopub.execute_input":"2025-10-30T22:41:01.38776Z","iopub.status.idle":"2025-10-30T22:41:01.394285Z","shell.execute_reply.started":"2025-10-30T22:41:01.387735Z","shell.execute_reply":"2025-10-30T22:41:01.392929Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Exploratory Data Analysis (EDA) & Data Visualization","metadata":{}},{"cell_type":"code","source":"# Alert level distributions\nplt.figure(figsize=(6,4))\nsns.countplot(x='alert', data=data, palette='magma')\nplt.title(\"Distribution of Earthquake Alert Levels\")\nplt.xlabel(\"Alert Level\")\nplt.ylabel(\"Count\")\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-30T22:41:01.395509Z","iopub.execute_input":"2025-10-30T22:41:01.395799Z","iopub.status.idle":"2025-10-30T22:41:01.590288Z","shell.execute_reply.started":"2025-10-30T22:41:01.395774Z","shell.execute_reply":"2025-10-30T22:41:01.589261Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Magnitude vs Depth by Alert\n\nplt.figure(figsize=(7,5))\nsns.scatterplot(x='depth', y='magnitude', hue='alert', data=data, palette='Set2')\nplt.title(\"Magnitude vs Depth by Alert Level\")\nplt.xlabel(\"Depth (km)\")\nplt.ylabel(\"Magnitude\")\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-30T22:41:01.591362Z","iopub.execute_input":"2025-10-30T22:41:01.591642Z","iopub.status.idle":"2025-10-30T22:41:01.929667Z","shell.execute_reply.started":"2025-10-30T22:41:01.591622Z","shell.execute_reply":"2025-10-30T22:41:01.928448Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Correlation heatmap\nplt.figure(figsize=(10,8))\nsns.heatmap(data.select_dtypes(include=np.number).corr(), annot=True, cmap='coolwarm', fmt='.2f')\nplt.title(\"Correlation Heatmap of Numerical Features\")\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-30T22:41:01.930951Z","iopub.execute_input":"2025-10-30T22:41:01.931411Z","iopub.status.idle":"2025-10-30T22:41:02.510252Z","shell.execute_reply.started":"2025-10-30T22:41:01.931375Z","shell.execute_reply":"2025-10-30T22:41:02.509289Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Plotly Bubble Map — Earthquake Distribution (1995–2023)\n\nimport plotly.express as px\nimport plotly.io as pio\n\n\npio.renderers.default = \"iframe\" \n\nfig = px.scatter_geo(\n    data,\n    lat='latitude',\n    lon='longitude',\n    color='alert',\n    size='magnitude',\n    hover_name='country',\n    projection='natural earth',\n    title=' Global Distribution of Earthquakes by Alert Level (1995–2023)',\n    color_discrete_sequence=px.colors.sequential.Plasma,\n    opacity=0.8,\n    size_max=15\n)\n\n# Optional: tweak layout for a cleaner, centered view\nfig.update_layout(\n    title_font=dict(size=18, family='Arial', color='black'),\n    geo=dict(\n        showcountries=True,\n        showland=True,\n        landcolor=\"rgb(217, 217, 217)\",\n        showocean=True,\n        oceancolor=\"rgb(200, 230, 255)\"\n    ),\n    legend_title_text='Alert Level'\n)\n\nfig.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-30T22:43:37.343299Z","iopub.execute_input":"2025-10-30T22:43:37.343644Z","iopub.status.idle":"2025-10-30T22:43:37.539254Z","shell.execute_reply.started":"2025-10-30T22:43:37.343619Z","shell.execute_reply":"2025-10-30T22:43:37.537498Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Magnitude Distribution by Continent\nplt.figure(figsize=(10,5))\nsns.boxplot(x='continent', y='magnitude', data=data[data['continent'] != 'Unknown'], palette='viridis')\nplt.xticks(rotation=45)\nplt.title(\"Distribution of Earthquake Magnitude by Continent\")\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-30T22:41:02.592394Z","iopub.execute_input":"2025-10-30T22:41:02.592782Z","iopub.status.idle":"2025-10-30T22:41:02.862018Z","shell.execute_reply.started":"2025-10-30T22:41:02.592751Z","shell.execute_reply":"2025-10-30T22:41:02.860403Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Pairplot for Key Seismic Features\n\nsns.pairplot(data, vars=['magnitude','depth','mmi','sig'], hue='alert', palette='coolwarm', corner=True)\nplt.suptitle(\"Pairwise Relationships Between Key Seismic Parameters\", y=1.02)\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-30T22:41:02.863155Z","iopub.execute_input":"2025-10-30T22:41:02.863507Z","iopub.status.idle":"2025-10-30T22:41:06.800811Z","shell.execute_reply.started":"2025-10-30T22:41:02.863479Z","shell.execute_reply":"2025-10-30T22:41:06.799568Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Model Development and Evaluation Framework based on Class-Imbalance Techniques","metadata":{}},{"cell_type":"code","source":" # ML models development and Evaluation\n\nfrom sklearn.model_selection import StratifiedShuffleSplit, RepeatedStratifiedKFold, cross_validate\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\nfrom sklearn.metrics import accuracy_score, f1_score\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom xgboost import XGBClassifier\nfrom sklearn.utils.class_weight import compute_class_weight\nfrom imblearn.over_sampling import SMOTE\nfrom imblearn.pipeline import Pipeline\n\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n\n# Encode categorical variables\n\ncat_cols = ['magType','continent','country','alert']\nle = LabelEncoder()\nfor col in cat_cols:\n    data[col] = le.fit_transform(data[col])\n\nX = data.drop(columns=['alert'])\ny = data['alert']\n\n\n# Stratified Shuffle Split (stable, class-balanced)\n\nsss = StratifiedShuffleSplit(n_splits=1, test_size=0.25, random_state=42)\nfor train_idx, test_idx in sss.split(X, y):\n    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled  = scaler.transform(X_test)\n\n# Evaluate on single test set\n\ndef evaluate_single(model, Xtr, ytr, Xte, yte, name, method):\n    model.fit(Xtr, ytr)\n    preds = model.predict(Xte)\n    acc = accuracy_score(yte, preds)\n    f1  = f1_score(yte, preds, average='macro')\n    print(f\"{method:10s} | {name:12s} | Acc={acc:.3f} | Macro-F1={f1:.3f}\")\n    return acc, f1\n\n\n# Robust Cross-Validation (RepeatedStratifiedKFold)\n\ncv = RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=42)\n\ndef cross_val_mean(model, X, y):\n    scores = cross_validate(model, X, y,\n                            cv=cv,\n                            scoring='f1_macro',\n                            n_jobs=-1,\n                            return_train_score=False)\n    return scores['test_score'].mean(), scores['test_score'].std()\n\n\n# Initialize Results Container\n\nresults = []\n\n\n# ML Models with mild regularization\n\nbase_models = {\n    \"LogReg\": LogisticRegression(max_iter=500, random_state=42, solver='lbfgs'),\n    \"RandomForest\": RandomForestClassifier(\n        n_estimators=150, max_depth=8, min_samples_split=4, random_state=42),\n    \"XGBoost\": XGBClassifier(\n        n_estimators=250, learning_rate=0.05, max_depth=5, subsample=0.8,\n        colsample_bytree=0.8, random_state=42, use_label_encoder=False)\n}\n\n# Class Imbalance techniques \n# 1. Baseline (no balancing)\n\nprint(\"\\n=== BASELINE ===\")\nfor name, model in base_models.items():\n    acc, f1 = evaluate_single(model, X_train_scaled, y_train, X_test_scaled, y_test, name, \"Baseline\")\n    cv_mean, cv_std = cross_val_mean(model, X_train_scaled, y_train)\n    results.append([\"Baseline\", name, acc, f1, cv_mean, cv_std])\n\n\n# 2. Class Weights\n\nprint(\"\\n=== CLASS WEIGHT ===\")\nweighted_models = {\n    \"LogReg\": LogisticRegression(max_iter=500, class_weight='balanced', random_state=42),\n    \"RandomForest\": RandomForestClassifier(\n        n_estimators=150, max_depth=8, min_samples_split=4,\n        class_weight='balanced', random_state=42),\n    \"XGBoost\": XGBClassifier(\n        n_estimators=250, learning_rate=0.05, max_depth=5,\n        subsample=0.8, colsample_bytree=0.8,\n        random_state=42, use_label_encoder=False)\n}\n\nfor name, model in weighted_models.items():\n    acc, f1 = evaluate_single(model, X_train_scaled, y_train, X_test_scaled, y_test, name, \"ClassWeight\")\n    cv_mean, cv_std = cross_val_mean(model, X_train_scaled, y_train)\n    results.append([\"ClassWeight\", name, acc, f1, cv_mean, cv_std])\n\n\n# 3. SMOTE (resampling inside each CV fold)\n\nprint(\"\\n=== SMOTE ===\")\nsm = SMOTE(random_state=42, k_neighbors=3)\nsmote_models = base_models.copy()\n\nfor name, base in smote_models.items():\n    # Pipeline for CV (SMOTE inside fold)\n    pipe = Pipeline([('scaler', StandardScaler()), ('smote', sm), ('model', base)])\n    cv_mean, cv_std = cross_val_mean(pipe, X_train, y_train)\n\n    # Hold-out single evaluation\n    X_res, y_res = sm.fit_resample(X_train_scaled, y_train)\n    acc, f1 = evaluate_single(base, X_res, y_res, X_test_scaled, y_test, name, \"SMOTE\")\n    results.append([\"SMOTE\", name, acc, f1, cv_mean, cv_std])\n\n\n# Compile Results\n\nresults_df = pd.DataFrame(results,\n    columns=[\"Technique\",\"Model\",\"Test_Acc\",\"Test_F1\",\"CV_F1_Mean\",\"CV_F1_STD\"]\n)\nresults_df = results_df.sort_values([\"Technique\",\"Test_F1\"], ascending=[True,False])\n\n# Table view\ndisplay(\n    results_df.style.background_gradient(cmap=\"YlGnBu\",\n        subset=[\"Test_Acc\",\"Test_F1\",\"CV_F1_Mean\"])\n    .format({\"Test_Acc\":\"{:.3f}\",\"Test_F1\":\"{:.3f}\",\"CV_F1_Mean\":\"{:.3f}\",\"CV_F1_STD\":\"{:.3f}\"})\n)\n\n\n# Ml Models comaprision Visualization (Test F1 Comparison)\n\nplt.figure(figsize=(12,8))\nax = sns.barplot(x=\"Technique\", y=\"Test_F1\", hue=\"Model\", data=results_df, palette=\"viridis\")\n\nplt.title(\"Model Comparison Based on Test Macro-F1 Score\")\nplt.ylabel(\"Test Macro-F1 Score\")\nplt.xlabel(\"Class-Imbalance Technique\")\n\nfor c in ax.containers:\n    ax.bar_label(c, fmt=\"%.3f\", label_type=\"edge\", fontsize=9, padding=2)\n\nplt.legend(title=\"Model\")\nplt.tight_layout()\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-30T22:41:06.802155Z","iopub.execute_input":"2025-10-30T22:41:06.802577Z","iopub.status.idle":"2025-10-30T22:41:28.197023Z","shell.execute_reply.started":"2025-10-30T22:41:06.802542Z","shell.execute_reply":"2025-10-30T22:41:28.195363Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Conclusion and future improvements\n\nThis project highlights the importance of addressing class imbalance to create fair and reliable earthquake alert predictions. Among the methods tested, Logistic Regression stood out as the top performer on the test set, while the combination of SMOTE and XGBoost provided the most balanced and consistent results across different folds. \n\nThe workflow, which focused on scaling, mild regularization, and repeated cross-validation, achieved impressive accuracy and stable Macro-F1 scores. Looking ahead, there are opportunities for improvement, such as fine-tuning hyperparameters, delving into advanced resampling techniques to boost model performance and generalization even further.","metadata":{}}]}